# Interpretable-Machine-Learning
Partial dependency plots and LIME &amp; SHAP interpretations
The code for PDP shows the marginal effect of one or two features on the predicted output of an ML model. It is simple and easy for non-technical audience to interpret the model.
In Feb-2014, 2 clients complained about the company's decision to market to them (or the lack of it). LIME and SHAP algorithms are used to calculate what particular features contributed to the decision for these two clients.
